{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:24<00:00, 40.30it/s]\n",
      "100%|██████████| 3125/3125 [01:32<00:00, 33.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0 Test set: Average loss: 6.9240, Accuracy: 90/50000 (0.2%)\n",
      "\n",
      "currnt lr:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:24<00:00, 40.80it/s]\n",
      "100%|██████████| 3125/3125 [01:32<00:00, 33.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 Test set: Average loss: 6.9283, Accuracy: 86/50000 (0.2%)\n",
      "\n",
      "currnt lr:0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:24<00:00, 40.68it/s]\n",
      "100%|██████████| 3125/3125 [01:31<00:00, 34.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2 Test set: Average loss: 6.9089, Accuracy: 65/50000 (0.1%)\n",
      "\n",
      "currnt lr:0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:24<00:00, 41.07it/s]\n",
      " 56%|█████▌    | 1753/3125 [00:52<00:41, 33.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4e2f62a06620>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0mprec1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0mlr_current\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-4e2f62a06620>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(epoch, test_width, recal)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from utils import *\n",
    "from mobilenetv2 import *\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "savepath = os.path.join('checkpoints', 'MobileNetV2', 'sr')\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True}\n",
    "\n",
    "model = mobilenetv2_w1(pretrained=True).cuda()\n",
    "\n",
    "#load dataset\n",
    "test_loader = getTestData('imagenet',\n",
    "                        batch_size=16,\n",
    "                        path='F:\\\\imagenet\\\\',\n",
    "                        for_inception=False)\n",
    "\n",
    "calibration_loader = getSelfBuiltCalibrationData('imagenet',\n",
    "                        batch_size=3,\n",
    "                        path='F:\\\\imagenet\\\\',\n",
    "                        for_inception=False)\n",
    "\n",
    "train_loader = getTrainingData('imagenet',  \n",
    "                        batch_size=3,\n",
    "                        path='F:\\\\imagenet\\\\',\n",
    "                        for_inception=False)\n",
    "\n",
    "best_prec1 = -1\n",
    "weight_decay=1e-4\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "resume=0\n",
    "epochs = 10\n",
    "start_epoch=0\n",
    "if resume:\n",
    "    if os.path.isfile(resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "        checkpoint = torch.load(resume)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {}) Prec1: {:f}\"\n",
    "              .format(resume, checkpoint['epoch'], best_prec1))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "        \n",
    "def updateBN():\n",
    "    s = 0.5e-5 #scale sparse rate (default: 0.0001)\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.grad.data.add_(s * torch.sign(m.weight.data))\n",
    "            \n",
    "def train():\n",
    "    sr = 1 #training with scale sparsity\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    train_acc = 0.\n",
    "    #for batch_idx, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "    for batch_idx, (data, target) in tqdm(enumerate(calibration_loader), total=len(calibration_loader)):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        avg_loss += loss.item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        loss.backward()\n",
    "        if sr:\n",
    "            updateBN()\n",
    "        optimizer.step()\n",
    "        \n",
    "def test(epoch,test_width=1.0,recal=False):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in tqdm(test_loader, total=len(test_loader)):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target, size_average=False).item()  # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nEpoch: {} Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(epoch,\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return correct.item() / float(len(test_loader.dataset))\n",
    "\n",
    "best_prec1 = 0.\n",
    "scheduler=optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=epochs,eta_min=0)\n",
    "start_epoch = 0\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    train()\n",
    "    prec1 = test(epoch=epoch)\n",
    "    scheduler.step(epoch)\n",
    "    lr_current = optimizer.param_groups[0]['lr']\n",
    "    print(\"currnt lr:{}\".format(lr_current))\n",
    "    is_best = prec1 > best_prec1\n",
    "    best_prec1 = max(prec1, best_prec1)\n",
    "    if is_best:\n",
    "        ckptfile = os.path.join(savepath, 'model_best.pth.tar')\n",
    "    else:\n",
    "        ckptfile = os.path.join(savepath, 'checkpoint.pth.tar')\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec1': best_prec1,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, ckptfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
